# Leveraging BERT for Natural Language Understanding of Domain-Specific Knowledge
 We experiment with fine-tuning BERT to jointly detect the userâ€™s intent and the related slots, using a custom-generated dataset built around a organization specific
knowledge base. Our results show that well-constructed datasets lead to high detection performances and the resulting model has the potential to enhance a future task-oriented dialogue system.

The model is part of a wider project, as it is trained using datasets generated with our Dialogue Simulator (check ...). It is intended to be incorporated as its NLU module, replacing the rule-based approach currently available in the system. More details available in the attached paper.

